# where to put example images in hdfs
example_data: /imgs/
# Also load a fuzzified version of the input examples for testing?
# if so, put an hdfs top level dir here.
# if not, put Null
fuzzy_example_data: /fuzzy/
# the wildcard input that specifies where to get hdfs images
input_spec: /imgs/*
# a name of a set of kmeans and on_each_image measurements
test_name: t1
# actions: list that may include some or all of 
#     [download, on_each_image, kmeans, find_similar]
actions: [download, on_each_image, kmeans, find_similar]
# If running find_similar, have the candidate images 
# already been through on_each_image?  
candidate_has_mapped: False

# Should the image analysis be larger to include
# all the images' quadrants as separate mapped images 
# (i.e. full image + 4 quandrants separately)  True/ False
quadrants: True
# For kmeans on one image, perceptive hash, and histogramming,
# rescale the image to this x pixel count then maintain aspect ratio
x_down: 128
# For ward clustering on each image, downscale x pixel count
# to this, then maintain aspect ratio.  (Ward clustering 
# is significantly slower than the other analyses, so 
# smaller size helps.)
ward_x_down: 32
# Perceptive hashes are hex strings in a list
# phash_chunk_len sets the sub-list length to
# find tokens with the perceptive hash list of hexes.
# Each perceptive hash should be this many bits
phash_bits: 64
# And this many of the phash N-bit hexes should
# be combined for keys typically
phash_chunk_len: 2
# The kmeans on the individual image is done on a sample
# to save time.  This is the max number of pixels to 
# include there.
kmeans_sample: 1400
# how many kmeans iterations on each individual image
maxIterations: 3
# how many kmeans clusters on each image's colors
n_clusters: 5
# how many clusters in the kmeans of all images together
n_clusters_group: 5
# ward clusters per image
ward_clusters: 20
# how many kmeans iterations in the group  kmeans of all images
max_iter_group: 1
# convergence in group kmeans 
# (summed pixel euclidean distance in a space where rows
#   are histograms and individual image's centroids flattened)
# The length of 'quantiles' below and 'n_clusters' influence this.
kmeans_group_converge: 10000 
# quantiles to get of each color histogram.  
# quantiles are a list of 0 to 100 based arguments to np.percentile
quantiles: [1, 2, 5, 15, 25, 50, 75, 85, 95, 98, 99]
# the reducers do some unions and counting
# of perceptive hash and ward label chunks
# this sets the number of keys in total
# that are held in memory that way.
in_memory_set_len: 8000000

kmeans_output: {
cluster_to_flattened: True,
cluster_to_key: True,
cluster_to_phash: True,
cluster_to_ward: True,
flattened_to_cluster: True,
flattened_to_key: True,
flattened_to_phash: True,
key_to_cluster: True,
key_to_phash: True,
phash_to_cluster: True,
phash_to_flattened: True,
phash_to_key: True,
ward_to_cluster: True,
ward_to_key: True
}


# The following arguments pertain to
# candidate images for which searches
# against the spark tables are being done.

# a name for a set of candidate images
candidate_batch: c1
# Where are the candidate images in hdfs
# this is a wildcard file spec
candidate_spec: /fuzzy/*
# The search proceeds in rounds of 
# searching networks of hashes.
# How many potentially matching image
# keys to keep on each round.
search_sample_step: 100
# What network depth of hash searching
search_rounds: 1



