# where to put example images in hdfs
example_data: /imgs/
# Also load a fuzzified version of the input examples for testing?
# if so, put an hdfs top level dir here.
# if not, put Null
fuzzy_example_data: /fuzzy/
# the wildcard input that specifies where to get hdfs images
input_spec: /imgs/*0.jpg
# a name of a set of kmeans and map_each_image measurements
test_name: t4
# actions: list that may include some or all of 
#     [map_each_image, kmeans, find_similar]
actions: [ map_each_image, kmeans, find_similar]
# If running find_similar, have the candidate images 
# already been through map_each_image?  
candidate_has_mapped: False

# Also consider the training/candidate images in patches?
# Set patch to Null to ignore or include the dictionary and 3 keys
# max_patches --> how many patches to randomly pull
# random_state --> integer seed or Null
# window_as_fraction ---> [x, y] that are multiplied by image size to get window 
#( window then is an argument for sklearn.feature_extraction.image.extract_patches_2d)
patch: {
max_patches: 4,
random_state: 0,
window_as_fraction: [0.5, 0.5]
}
# For kmeans on one image, perceptive hash, and histogramming,
# rescale the image to this x pixel count then maintain aspect ratio
x_down: 32
# For ward clustering on each image, downscale x pixel count
# to this, then maintain aspect ratio.  (Ward clustering 
# is significantly slower than the other analyses, so 
# smaller size helps.)
ward_x_down: 16
# Perceptive hashes are hex strings in a list
# phash_chunk_len sets the sub-list length to
# find tokens with the perceptive hash list of hexes.
# Each perceptive hash should be this many bits
phash_bits: 256
# And this many of the phash N-bit hexes should
# be combined for keys typically
phash_chunk_len: 2
# The kmeans on the individual image is done on a sample
# to save time.  This is the max number of pixels to 
# include there.
kmeans_sample: 2000
# how many kmeans iterations on each individual image
maxIterations: 15
# how many kmeans clusters on each image's colors
n_clusters: 12
# how many clusters in the kmeans of all images together
n_clusters_group: 8
# ward clusters per image.  Keeping this small 
# can reduce the size of the join operation at the 
# find_similar step. (i.e. 1 hash per cluster 
# per selection per training image joined to 
# candidates with same.)
ward_clusters: 5
# how many kmeans iterations in the group  kmeans of all images
max_iter_group: 3
# convergence in group kmeans 
# (summed pixel euclidean distance in a space where rows
#   are histograms and individual image's centroids flattened)
# The length of 'quantiles' below and 'n_clusters' influence this.
kmeans_group_converge: Null 
# quantiles to get of each color histogram.  
# quantiles are a list of 0 to 100 based arguments to np.percentile
quantiles: [5, 15, 25, 50,  75, 85 ,95]
# the reducers do some unions and counting
# of perceptive hash and ward cluster hash chunks.
# this sets the number of keys in total
# that are held in memory that way.
in_memory_set_len: 8000000

#This dictionary, kmeans_output, sets
# all the lookup tables to create after
# kmeans iterations are done.  
# NOTE. Not all combinations are consistent
# with the find_similar step as written.
kmeans_output: {
cluster_to_flattened: True,
cluster_to_key: True,
cluster_to_phash: True,
cluster_to_ward: True,
flattened_to_cluster: True,
flattened_to_key: True,
flattened_to_phash: True,
key_to_cluster: True,
key_to_phash: True,
phash_to_cluster: True,
phash_to_flattened: True,
phash_to_key: True,
ward_to_cluster: True,
ward_to_key: True
}


# The following arguments pertain to
# candidate images for which searches
# against the spark tables are being done.

# a name for a set of candidate images
candidate_batch: c4
# where should the measurements be saved, or
# if indicated True candidate_has_mapped above, then
# it is assumed map_each_image has been applied to candidate batch.
candidate_measures_spec: /t4/candidates/c4/measures
# Where are the candidate images in hdfs
# this is a wildcard file spec
candidate_spec: /fuzzy/*0.jpg
# The search proceeds in rounds of 
# searching networks of hashes.
# How many potentially matching image
# keys to keep on each round.
search_sample_step: 100
# What network depth of hash searching
# Note this is a placeholder and 
# should remain at 1 until
# find_similar function is improved.
search_rounds: 1



